1. Identify the document sources: Determine the sources of the documents you want to extract information from, and make sure you have access to them in a machine-readable format.

2. Extract text from the documents: Use textract to extract the text from the documents.

3. Perform natural language processing: Use spaCy to perform natural language processing on the extracted text. This can include tasks such as sentence segmentation, part-of-speech tagging, named entity recognition, and dependency parsing.

4. Identify relevant concepts and relationships: Use the output from the NLP processing to identify relevant concepts and relationships between them. This can involve identifying key phrases, relationships between phrases, and identifying entities and their properties.

5. Generate the UML diagram: Use PlantUML to generate the UML diagram based on the identified concepts and relationships.


As applied to documenting how a computer system is structured:

Preprocessing: Convert the written descriptions of the computer subsystems into machine-readable text, and preprocess the text to remove any irrelevant information such as headers and footers. 

SpaCy:

Tokenization: Tokenize the text into individual words or phrases.

Part-of-speech (POS) tagging: Tag each token with its corresponding part of speech, such as noun or verb.

Named entity recognition (NER): Identify named entities in the text, such as specific computer components like "memory," "processor," and "graphics card."

Dependency parsing: Analyze the relationships between tokens in the text, such as which components are connected to each other.

PlantUML:

UML diagram generation: Generate a UML diagram based on the extracted components and their relationships.